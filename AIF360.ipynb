{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experient imputation methods with AIF360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.completer import complete_by_mean_col, complete_by_mean_col_v2\n",
    "from utils.completer import complete_by_multi, complete_by_multi_v2\n",
    "from utils.completer import complete_by_similar_row, complete_by_similar_row_v2\n",
    "from utils.generator import gen_complete_random\n",
    "from utils.data import create_adult_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Fair Representations (LFR)\n",
    "[example notebook](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_lfr.ipynb)  \n",
    "\n",
    "------\n",
    "\n",
    "The idea is to first apply imputation on original dataset (adult dataset here)  \n",
    "Then feed the converted dataset into LFR to see any difference  \n",
    "\n",
    "------\n",
    "\n",
    "Note:  \n",
    "In order to LFR to work on Python3.8  \n",
    "Should install LFR directly from github, instead of from pip  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "from aif360.algorithms.preprocessing.lfr import LFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32561, 10)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "data = create_adult_dataset()\n",
    "print(data.X.shape)\n",
    "print(data.X.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen_complete_random: 58244 NaN values have been inserted\n",
      "age               6435\n",
      "workclass         6423\n",
      "education         6525\n",
      "education-num     6467\n",
      "marital-status    6544\n",
      "occupation        6499\n",
      "relationship      6471\n",
      "race              6383\n",
      "hours-per-week    6497\n",
      "sex                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_incomplete = gen_complete_random(data, random_ratio=0.2)\n",
    "print(data_incomplete.X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age               0\n",
      "workclass         0\n",
      "education         0\n",
      "education-num     0\n",
      "marital-status    0\n",
      "occupation        0\n",
      "relationship      0\n",
      "race              0\n",
      "hours-per-week    0\n",
      "sex               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_complete = complete_by_mean_col(data_incomplete)\n",
    "print(data_complete.X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_complete.y_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['workclass',\n",
       " 'education',\n",
       " 'marital-status',\n",
       " 'occupation',\n",
       " 'relationship',\n",
       " 'race']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_complete.categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_complete.protected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22792, 11)\n",
      "(9769, 11)\n"
     ]
    }
   ],
   "source": [
    "# convert to standard dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "tmp_df = pd.concat([data_complete.X, pd.DataFrame(data_complete.y, columns=[\"_TARGET_\"])], axis=1).copy()\n",
    "tmp_df['sex'] = tmp_df['sex'].apply(lambda x : 0.0 if x == ' Female' else 1.0) # necessary for aif360 to understand\n",
    "tmp_df_train, tmp_df_test = train_test_split(tmp_df, test_size=0.3, shuffle=True)\n",
    "data_imputed_train = StandardDataset(df=tmp_df_train, label_name=\"_TARGET_\", favorable_classes=lambda x: x > 0,\n",
    "                                     protected_attribute_names=['sex'], privileged_classes=[[1.0]],\n",
    "                                     features_to_keep=data_complete.X.columns.tolist(),\n",
    "                                     instance_weights_name=None, features_to_drop=[],\n",
    "                                     custom_preprocessing=None, categorical_features=data_complete.categorical_features)\n",
    "data_imputed_test = StandardDataset(df=tmp_df_test, label_name=\"_TARGET_\", favorable_classes=lambda x: x > 0,\n",
    "                                    protected_attribute_names=['sex'], privileged_classes=[[1.0]],\n",
    "                                    features_to_keep=data_complete.X.columns.tolist(),\n",
    "                                    instance_weights_name=None, features_to_drop=[],\n",
    "                                    custom_preprocessing=None, categorical_features=data_complete.categorical_features)\n",
    "print(tmp_df_train.shape)\n",
    "print(tmp_df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.19845762081733645\n",
      "-0.1911858703853891\n"
     ]
    }
   ],
   "source": [
    "privileged_groups = [{'sex': 1.0}]\n",
    "unprivileged_groups = [{'sex': 0.0}]\n",
    "metric_imputed_train = BinaryLabelDatasetMetric(data_imputed_train, \n",
    "                                                unprivileged_groups=unprivileged_groups,\n",
    "                                                privileged_groups=privileged_groups)\n",
    "metric_imputed_test = BinaryLabelDatasetMetric(data_imputed_test, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "print(metric_imputed_train.mean_difference())\n",
    "print(metric_imputed_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "data_imputed_train.features = scaler.fit_transform(data_imputed_train.features)\n",
    "data_imputed_test.features = scaler.transform(data_imputed_test.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.9896145477518621, L_x: 2.5506503453342653,  L_y: 0.7247481625639295,  L_z: 0.004900675327253022\n",
      "step: 250, loss: 0.9896145225098801, L_x: 2.5506503674769796,  L_y: 0.724748137237789,  L_z: 0.0049006742621965655\n",
      "step: 500, loss: 0.9896145466012233, L_x: 2.550650371640526,  L_y: 0.7247481673870411,  L_z: 0.004900671025064818\n",
      "step: 750, loss: 0.8871006796057351, L_x: 2.5495404005205486,  L_y: 0.6228296373355169,  L_z: 0.0046585011090816645\n",
      "step: 1000, loss: 0.8871006870140217, L_x: 2.5495404069945944,  L_y: 0.6228296468793166,  L_z: 0.004658499717622798\n",
      "step: 1250, loss: 0.8871006667299441, L_x: 2.5495404001849726,  L_y: 0.622829621281813,  L_z: 0.004658502714816913\n",
      "step: 1500, loss: 0.8117905572462389, L_x: 2.5456845610942844,  L_y: 0.5484700846652261,  L_z: 0.0043760082357922215\n",
      "step: 1750, loss: 0.8117905495159956, L_x: 2.545684568923784,  L_y: 0.5484700793038377,  L_z: 0.004376006659889686\n",
      "step: 2000, loss: 0.8065109955517435, L_x: 2.543394127179285,  L_y: 0.5445916773790536,  L_z: 0.0037899527273807174\n",
      "step: 2250, loss: 0.8065109918700195, L_x: 2.543394152690966,  L_y: 0.544591673053973,  L_z: 0.0037899517734749574\n",
      "step: 2500, loss: 0.8065109937926566, L_x: 2.5433941211072826,  L_y: 0.544591684083002,  L_z: 0.003789948799463204\n",
      "step: 2750, loss: 0.8017811400518065, L_x: 2.5398753557169895,  L_y: 0.5410450050097126,  L_z: 0.003374299735197407\n",
      "step: 3000, loss: 0.8017811800949619, L_x: 2.5398753716823546,  L_y: 0.541045017897176,  L_z: 0.0033743125147752476\n",
      "step: 3250, loss: 0.7939201781962963, L_x: 2.529312509660345,  L_y: 0.5359434827872582,  L_z: 0.0025227222215017915\n",
      "step: 3500, loss: 0.7939201609146067, L_x: 2.529312523885523,  L_y: 0.5359434622823016,  L_z: 0.0025227231218763898\n",
      "step: 3750, loss: 0.7939201684863757, L_x: 2.5293125059526216,  L_y: 0.5359434709316004,  L_z: 0.0025227234797565628\n",
      "step: 4000, loss: 0.7855974614649031, L_x: 2.5116141046389697,  L_y: 0.529919088600691,  L_z: 0.0022584812001574723\n",
      "step: 4250, loss: 0.7855974630997485, L_x: 2.511614091690679,  L_y: 0.5299190903888896,  L_z: 0.002258481770895532\n",
      "step: 4500, loss: 0.7817749643514323, L_x: 2.475808349497438,  L_y: 0.5231438639864922,  L_z: 0.0055251327075981835\n",
      "step: 4750, loss: 0.7817749501305771, L_x: 2.475808345723051,  L_y: 0.5231438556466436,  L_z: 0.005525129955814216\n",
      "step: 5000, loss: 0.7817749522402601, L_x: 2.475808355687084,  L_y: 0.5231438555344251,  L_z: 0.005525130568563236\n"
     ]
    }
   ],
   "source": [
    "TR = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
    "         verbose=1\n",
    "        )\n",
    "TR = TR.fit(data_imputed_train, maxiter=5000, maxfun=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      1.00      0.86      7432\n",
      "         1.0       0.00      0.00      0.00      2337\n",
      "\n",
      "    accuracy                           0.76      9769\n",
      "   macro avg       0.38      0.50      0.43      9769\n",
      "weighted avg       0.58      0.76      0.66      9769\n",
      "\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data_imputed_transf_train = TR.transform(data_imputed_train)\n",
    "data_imputed_transf_test = TR.transform(data_imputed_test)\n",
    "print(classification_report(data_imputed_test.labels, data_imputed_transf_test.labels, zero_division=0))\n",
    "metric_imputed_transf_train = BinaryLabelDatasetMetric(data_imputed_transf_train, \n",
    "                                                       unprivileged_groups=unprivileged_groups,\n",
    "                                                       privileged_groups=privileged_groups)\n",
    "metric_imputed_transf_test = BinaryLabelDatasetMetric(data_imputed_transf_test, \n",
    "                                                      unprivileged_groups=unprivileged_groups,\n",
    "                                                      privileged_groups=privileged_groups)\n",
    "print(metric_imputed_transf_train.mean_difference())\n",
    "print(metric_imputed_transf_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22792, 11)\n",
      "(9769, 11)\n",
      "-0.19347587452471865\n",
      "-0.20266969567058415\n"
     ]
    }
   ],
   "source": [
    "# compare with original dataset\n",
    "tmp_df = pd.concat([data.X, pd.DataFrame(data.y, columns=[\"_TARGET_\"])], axis=1).copy()\n",
    "tmp_df['sex'] = tmp_df['sex'].apply(lambda x : 0.0 if x == ' Female' else 1.0) # necessary for aif360 to understand\n",
    "tmp_df_train, tmp_df_test = train_test_split(tmp_df, test_size=0.3, shuffle=True)\n",
    "data_train = StandardDataset(df=tmp_df_train, label_name=\"_TARGET_\", favorable_classes=lambda x: x > 0,\n",
    "                             protected_attribute_names=['sex'], privileged_classes=[[1.0]],\n",
    "                             features_to_keep=data_complete.X.columns.tolist(),\n",
    "                             instance_weights_name=None, features_to_drop=[],\n",
    "                             custom_preprocessing=None, categorical_features=data_complete.categorical_features)\n",
    "data_test = StandardDataset(df=tmp_df_test, label_name=\"_TARGET_\", favorable_classes=lambda x: x > 0,\n",
    "                            protected_attribute_names=['sex'], privileged_classes=[[1.0]],\n",
    "                            features_to_keep=data_complete.X.columns.tolist(),\n",
    "                            instance_weights_name=None, features_to_drop=[],\n",
    "                            custom_preprocessing=None, categorical_features=data_complete.categorical_features)\n",
    "print(tmp_df_train.shape)\n",
    "print(tmp_df_test.shape)\n",
    "metric_train = BinaryLabelDatasetMetric(data_train, \n",
    "                                        unprivileged_groups=unprivileged_groups,\n",
    "                                        privileged_groups=privileged_groups)\n",
    "metric_test = BinaryLabelDatasetMetric(data_test, \n",
    "                                       unprivileged_groups=unprivileged_groups,\n",
    "                                       privileged_groups=privileged_groups)\n",
    "print(metric_train.mean_difference())\n",
    "print(metric_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.9310241358214724, L_x: 2.5070259834670834,  L_y: 0.6630164435129302,  L_z: 0.008652546980916876\n",
      "step: 250, loss: 0.9310241479293173, L_x: 2.5070260229606296,  L_y: 0.6630164577066221,  L_z: 0.008652543963316179\n",
      "step: 500, loss: 0.9310241410569131, L_x: 2.5070259908939905,  L_y: 0.6630164383652646,  L_z: 0.008652551801124758\n",
      "step: 750, loss: 0.8713837661082762, L_x: 2.506429235381934,  L_y: 0.6041444579964163,  L_z: 0.008298192286833256\n",
      "step: 1000, loss: 0.871383764195668, L_x: 2.506429213277862,  L_y: 0.6041444603712717,  L_z: 0.008298191248305038\n",
      "step: 1250, loss: 0.8713837705198791, L_x: 2.5064292281649134,  L_y: 0.6041444692179301,  L_z: 0.008298189242728864\n",
      "step: 1500, loss: 0.8286751898569678, L_x: 2.5038802214802947,  L_y: 0.5647548948882384,  L_z: 0.006766136410349978\n",
      "step: 1750, loss: 0.8286751987845065, L_x: 2.503880180373343,  L_y: 0.5647549103926711,  L_z: 0.006766135177250582\n",
      "step: 2000, loss: 0.8230262234325005, L_x: 2.502949838919146,  L_y: 0.5606182925854727,  L_z: 0.006056473477556651\n",
      "step: 2250, loss: 0.8230262283139362, L_x: 2.502949828616649,  L_y: 0.5606182926732765,  L_z: 0.0060564763894974906\n",
      "step: 2500, loss: 0.8230262263577085, L_x: 2.502949840083234,  L_y: 0.5606182901879225,  L_z: 0.0060564760807312835\n",
      "step: 2750, loss: 0.8066156416841165, L_x: 2.495594112961129,  L_y: 0.5489888734818464,  L_z: 0.004033678453078553\n",
      "step: 3000, loss: 0.8066156092997341, L_x: 2.4955940954689773,  L_y: 0.5489888493579482,  L_z: 0.004033675197444071\n",
      "step: 3250, loss: 0.7986838508780488, L_x: 2.488635546723971,  L_y: 0.543570743390599,  L_z: 0.0031247764075264125\n",
      "step: 3500, loss: 0.7986838477500698, L_x: 2.488635543425217,  L_y: 0.5435707411674962,  L_z: 0.0031247761200259836\n",
      "step: 3750, loss: 0.7986838497074621, L_x: 2.4886355479815796,  L_y: 0.5435707422147571,  L_z: 0.003124776347273531\n",
      "step: 4000, loss: 0.7875020890118198, L_x: 2.4681420067764117,  L_y: 0.5334776789967758,  L_z: 0.0036051046687014645\n",
      "step: 4250, loss: 0.7875020895775029, L_x: 2.4681419858203517,  L_y: 0.5334776825022729,  L_z: 0.003605104246597432\n",
      "step: 4500, loss: 0.7776769890315023, L_x: 2.4559316567328953,  L_y: 0.5249082264267625,  L_z: 0.003587798465725074\n",
      "step: 4750, loss: 0.7776769835596492, L_x: 2.4559316334186363,  L_y: 0.5249082225461681,  L_z: 0.0035877988358087127\n",
      "step: 5000, loss: 0.7776769889193469, L_x: 2.455931654630038,  L_y: 0.5249082226467212,  L_z: 0.0035878004048109135\n"
     ]
    }
   ],
   "source": [
    "data_train.features = scaler.fit_transform(data_train.features)\n",
    "data_test.features = scaler.transform(data_test.features)\n",
    "TR = LFR(unprivileged_groups=unprivileged_groups,\n",
    "         privileged_groups=privileged_groups,\n",
    "         k=10, Ax=0.1, Ay=1.0, Az=2.0,\n",
    "         verbose=1\n",
    "        )\n",
    "TR = TR.fit(data_train, maxiter=5000, maxfun=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.76      1.00      0.87      7459\n",
      "         1.0       0.00      0.00      0.00      2310\n",
      "\n",
      "    accuracy                           0.76      9769\n",
      "   macro avg       0.38      0.50      0.43      9769\n",
      "weighted avg       0.58      0.76      0.66      9769\n",
      "\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "data_transf_train = TR.transform(data_train)\n",
    "data_transf_test = TR.transform(data_test)\n",
    "print(classification_report(data_test.labels, data_transf_test.labels, zero_division=0))\n",
    "metric_transf_train = BinaryLabelDatasetMetric(data_transf_train, \n",
    "                                               unprivileged_groups=unprivileged_groups,\n",
    "                                               privileged_groups=privileged_groups)\n",
    "metric_transf_test = BinaryLabelDatasetMetric(data_transf_test, \n",
    "                                              unprivileged_groups=unprivileged_groups,\n",
    "                                              privileged_groups=privileged_groups)\n",
    "print(metric_transf_train.mean_difference())\n",
    "print(metric_transf_test.mean_difference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
