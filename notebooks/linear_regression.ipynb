{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression  \n",
    "A Linear Regression function to find the coefficients based on ratio analysis outputs  \n",
    "in order to find the trade off between bias (bias1 or bias2) and target value (accuracy or f1 score)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from script_single_task import random_ratios, acc, f1score, bias1, bias2, newBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_INPUT_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_per_ratio = 200\n",
    "classifiers = [\"KNN\", \"LinearSVC\", \"SVC\", \"Forest\", \"LogReg\", \"Tree\", \"MLP\"]\n",
    "methods = [\"mean_v1\", \"mean_v2\", \"similar_v1\", \"similar_v2\", \"multi_v1\", \"multi_v2\"]\n",
    "data_columns_1 = [\"iter_number\", \"random_ratio\", \"ml_name\", \"method_name\", \"bias1\", \"bias2\", \"new_bias\", \"accuracy\", \"f1_score\", \"real_accuracy\"]\n",
    "data_columns_2 = [\"iter_number\", \"random_ratio\"] + \\\n",
    "                 [\"ML_{}\".format(x) for x in classifiers] + \\\n",
    "                 [\"Imp_{}\".format(x) for x in methods] + \\\n",
    "                 [\"bias1\", \"bias2\", \"new_bias\", \"accuracy\", \"f1_score\", \"real_accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_name, target_name=\"acc\", file_name=None):\n",
    "    if os.path.exists(file_name):\n",
    "        return pd.read_csv(file_name)\n",
    "    global classifiers, methods, data_columns\n",
    "    data_final = []\n",
    "    for method in methods:\n",
    "        if not os.path.exists(os.path.join(\"condor_outputs\", target_name, dataset_name, \"{}.pkl\".format(method))):\n",
    "            raise Exception(\"Required pkl not found: {}\".format(os.path.join(\"condor_outputs\", target_name, dataset_name, \"{}.pkl\".format(method))))\n",
    "        with open(os.path.join(\"condor_outputs\", target_name, dataset_name, \"{}.pkl\".format(method)), \"rb\") as inFile:\n",
    "            pkl_data = pickle.load(inFile)\n",
    "        j = 0\n",
    "        for i in range(0, len(pkl_data), iter_per_ratio):\n",
    "            i_data = pkl_data[i:(i+iter_per_ratio)]\n",
    "            for clf in classifiers:\n",
    "                clf_data = [x[clf] for x in i_data]\n",
    "                for cf_matrices in clf_data:\n",
    "                    # [[acc avg], [bias1], [bias2], [f1 score], [real acc], [new bias]], remove -1, [None] cases\n",
    "                    data_processed = [[], [], [], [], [], []]\n",
    "                    for mm in cf_matrices:\n",
    "                        if len(mm) < 1:\n",
    "                            continue\n",
    "                        cf_m, acc_m = mm[0], mm[1]\n",
    "                    try:\n",
    "                        x = acc(cf_m)\n",
    "                        y = bias1(cf_m)\n",
    "                        z = bias2(cf_m)\n",
    "                        w = f1score(cf_m)\n",
    "                        k = newBias(cf_m)\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "                    if (y > 0) and (z > 0) and len(w) == 2:\n",
    "                        data_processed[0].append(x)\n",
    "                        data_processed[1].append(y)\n",
    "                        data_processed[2].append(z)\n",
    "                        data_processed[3].append(np.mean(w))\n",
    "                        data_processed[4].append(acc_m)\n",
    "                        data_processed[5].append(k)\n",
    "                    row_data = [i // iter_per_ratio, round(random_ratios[j], 2), clf, method, np.mean(data_processed[1]),\n",
    "                                np.mean(data_processed[2]), np.mean(data_processed[5]),\n",
    "                                np.mean(data_processed[0]), np.mean(data_processed[3]),\n",
    "                                np.mean(data_processed[4])]\n",
    "                    data_final.append(row_data)\n",
    "            j+=1\n",
    "    data_final = pd.DataFrame(data_final, columns=data_columns_1)\n",
    "    if file_name:\n",
    "        data_final.to_csv(file_name, index=False)\n",
    "    return data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titanic Dataset as Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CREATE_INPUT_DATASET:\n",
    "    data = prepare_dataset(\"titanic\", \"acc\", os.path.join(\"ratio_analysis_plots\", \"d_titanic.csv\"))\n",
    "else:\n",
    "    data = pd.read_csv(os.path.join(\"ratio_analysis_plots\", \"d_titanic.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138895, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove empty columns\n",
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.618392\n",
       "bias1        0.002460\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc_bias1 = smf.ols(formula=\"accuracy ~ bias1\", data=data).fit()\n",
    "result_acc_bias1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.602350\n",
       "bias2        0.013663\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc_bias2 = smf.ols(formula=\"accuracy ~ bias2\", data=data).fit()\n",
    "result_acc_bias2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    0.590758\n",
       "new_bias     0.074345\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_acc_bias_new = smf.ols(formula=\"accuracy ~ new_bias\", data=data).fit()\n",
    "result_acc_bias_new.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute and collect to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: titanic, shape: (138895, 10)\n",
      "Dataset: german, shape: (153088, 10)\n",
      "Dataset: juvenile, shape: (157383, 10)\n",
      "Dataset: compas, shape: (167813, 10)\n",
      "Dataset: adult, shape: (163793, 10)\n",
      "Dataset: communities, shape: (127403, 10)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"titanic\", \"german\", \"juvenile\", \"compas\", \"adult\", \"communities\"]\n",
    "target = \"acc\"\n",
    "sheet_data1 = []\n",
    "sheet_data2 = []\n",
    "sheet_data3 = []\n",
    "sheet_col1 = [\"data_name\", \"bias1\", \"ml_name\", \"method_name\", \"Intercept\"]\n",
    "sheet_col2 = [\"data_name\", \"bias2\", \"ml_name\", \"method_name\", \"Intercept\"]\n",
    "sheet_col3 = [\"data_name\", \"new_bias\", \"ml_name\", \"method_name\", \"Intercept\"]\n",
    "for data_name in datasets:\n",
    "    if CREATE_INPUT_DATASET:\n",
    "        data = prepare_dataset(data_name, target, os.path.join(\"ratio_analysis_plots\", \"d_{}.csv\".format(data_name)))\n",
    "    else:\n",
    "        data = pd.read_csv(os.path.join(\"ratio_analysis_plots\", \"d_{}.csv\".format(data_name)))\n",
    "    data.dropna(inplace=True)\n",
    "    print(\"Dataset: {}, shape: {}\".format(data_name, data.shape))\n",
    "    for clf in classifiers:\n",
    "        for method in methods:\n",
    "            data_copy = data[data[\"ml_name\"] == clf].copy()\n",
    "            data_copy = data_copy[data_copy[\"method_name\"] == method].copy()\n",
    "            result_acc_bias1 = smf.ols(formula=\"accuracy ~ bias1\", data=data_copy).fit().params.tolist()\n",
    "            result_acc_bias2 = smf.ols(formula=\"accuracy ~ bias2\", data=data_copy).fit().params.tolist()\n",
    "            result_acc_bias_new = smf.ols(formula=\"accuracy ~ new_bias\", data=data_copy).fit().params.tolist()\n",
    "            sheet_data1.append([data_name, result_acc_bias1[1], clf, method, result_acc_bias1[0]])\n",
    "            sheet_data2.append([data_name, result_acc_bias2[1], clf, method, result_acc_bias2[0]])\n",
    "            sheet_data3.append([data_name, result_acc_bias_new[1], clf, method, result_acc_bias_new[0]])\n",
    "with pd.ExcelWriter(os.path.join(\"ratio_analysis_plots\", \"d_collected_acc.xlsx\")) as writer:\n",
    "    pd.DataFrame(sheet_data1, columns=sheet_col1).to_excel(writer, sheet_name=\"bias1\")\n",
    "    pd.DataFrame(sheet_data2, columns=sheet_col2).to_excel(writer, sheet_name=\"bias2\")\n",
    "    pd.DataFrame(sheet_data3, columns=sheet_col3).to_excel(writer, sheet_name=\"new_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: titanic, shape: (138895, 10)\n",
      "Dataset: german, shape: (153088, 10)\n",
      "Dataset: juvenile, shape: (157383, 10)\n",
      "Dataset: compas, shape: (167813, 10)\n",
      "Dataset: adult, shape: (163793, 10)\n",
      "Dataset: communities, shape: (127403, 10)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"titanic\", \"german\", \"juvenile\", \"compas\", \"adult\", \"communities\"]\n",
    "target = \"acc\"\n",
    "sheet_data1 = []\n",
    "sheet_data2 = []\n",
    "sheet_data3 = []\n",
    "sheet_data4 = []\n",
    "sheet_col = [\"data_name\", \"random_ratio\", \"ml_name\", \"method_name\", \"Intercept\"]\n",
    "for data_name in datasets:\n",
    "    if CREATE_INPUT_DATASET:\n",
    "        data = prepare_dataset(data_name, target, os.path.join(\"ratio_analysis_plots\", \"d_{}.csv\".format(data_name)))\n",
    "    else:\n",
    "        data = pd.read_csv(os.path.join(\"ratio_analysis_plots\", \"d_{}.csv\".format(data_name)))\n",
    "    data.dropna(inplace=True)\n",
    "    print(\"Dataset: {}, shape: {}\".format(data_name, data.shape))\n",
    "    for clf in classifiers:\n",
    "        for method in methods:\n",
    "            data_copy = data[data[\"ml_name\"] == clf].copy()\n",
    "            data_copy = data_copy[data_copy[\"method_name\"] == method].copy()\n",
    "            result_acc = smf.ols(formula=\"accuracy ~ random_ratio\", data=data_copy).fit().params.tolist()\n",
    "            result_bias1 = smf.ols(formula=\"bias1 ~ random_ratio\", data=data_copy).fit().params.tolist()\n",
    "            result_bias2 = smf.ols(formula=\"bias2 ~ random_ratio\", data=data_copy).fit().params.tolist()\n",
    "            result_bias_new = smf.ols(formula=\"new_bias ~ random_ratio\", data=data_copy).fit().params.tolist()\n",
    "            sheet_data1.append([data_name, result_acc[1], clf, method, result_acc[0]])\n",
    "            sheet_data2.append([data_name, result_bias1[1], clf, method, result_bias1[0]])\n",
    "            sheet_data3.append([data_name, result_bias2[1], clf, method, result_bias2[0]])\n",
    "            sheet_data4.append([data_name, result_bias_new[1], clf, method, result_bias_new[0]])\n",
    "with pd.ExcelWriter(os.path.join(\"ratio_analysis_plots\", \"d_collected_ratio.xlsx\")) as writer:\n",
    "    pd.DataFrame(sheet_data1, columns=sheet_col).to_excel(writer, sheet_name=\"accuracy\")\n",
    "    pd.DataFrame(sheet_data2, columns=sheet_col).to_excel(writer, sheet_name=\"bias1\")\n",
    "    pd.DataFrame(sheet_data3, columns=sheet_col).to_excel(writer, sheet_name=\"bias2\")\n",
    "    pd.DataFrame(sheet_data4, columns=sheet_col).to_excel(writer, sheet_name=\"new_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: titanic, shape: (138895, 10)\n",
      "Dataset: german, shape: (153088, 10)\n",
      "Dataset: juvenile, shape: (157383, 10)\n",
      "Dataset: compas, shape: (167813, 10)\n",
      "Dataset: adult, shape: (163793, 10)\n",
      "Dataset: communities, shape: (127403, 10)\n"
     ]
    }
   ],
   "source": [
    "datasets = [\"titanic\", \"german\", \"juvenile\", \"compas\", \"adult\", \"communities\"]\n",
    "target = \"acc\"\n",
    "sheet_data1 = []\n",
    "sheet_data2 = []\n",
    "sheet_data3 = []\n",
    "sheet_data4 = []\n",
    "sheet_col = [\"data_name\", \"random_ratio\", \"random_ratio^2\", \"ml_name\", \"method_name\", \"Intercept\"]\n",
    "for data_name in datasets:\n",
    "    if CREATE_INPUT_DATASET:\n",
    "        data = prepare_dataset(data_name, target, os.path.join(\"ratio_analysis_plots\", \"d_{}.csv\".format(data_name)))\n",
    "    else:\n",
    "        data = pd.read_csv(os.path.join(\"ratio_analysis_plots\", \"d_{}.csv\".format(data_name)))\n",
    "    data.dropna(inplace=True)\n",
    "    print(\"Dataset: {}, shape: {}\".format(data_name, data.shape))\n",
    "    data[\"random_ratio2\"] = np.square(data[\"random_ratio\"])\n",
    "    for clf in classifiers:\n",
    "        for method in methods:\n",
    "            data_copy = data[data[\"ml_name\"] == clf].copy()\n",
    "            data_copy = data_copy[data_copy[\"method_name\"] == method].copy()\n",
    "            result_acc = smf.ols(formula=\"accuracy ~ random_ratio + random_ratio2\", data=data_copy).fit().params.tolist()\n",
    "            result_bias1 = smf.ols(formula=\"bias1 ~ random_ratio + random_ratio2\", data=data_copy).fit().params.tolist()\n",
    "            result_bias2 = smf.ols(formula=\"bias2 ~ random_ratio + random_ratio2\", data=data_copy).fit().params.tolist()\n",
    "            result_bias_new = smf.ols(formula=\"new_bias ~ random_ratio + random_ratio2\", data=data_copy).fit().params.tolist()\n",
    "            sheet_data1.append([data_name, result_acc[1], result_acc[2], clf, method, result_acc[0]])\n",
    "            sheet_data2.append([data_name, result_bias1[1], result_bias1[2], clf, method, result_bias1[0]])\n",
    "            sheet_data3.append([data_name, result_bias2[1], result_bias2[2], clf, method, result_bias2[0]])\n",
    "            sheet_data4.append([data_name, result_bias_new[1], result_bias_new[2], clf, method, result_bias_new[0]])\n",
    "with pd.ExcelWriter(os.path.join(\"ratio_analysis_plots\", \"d_collected_ratio2.xlsx\")) as writer:\n",
    "    pd.DataFrame(sheet_data1, columns=sheet_col).to_excel(writer, sheet_name=\"accuracy\")\n",
    "    pd.DataFrame(sheet_data2, columns=sheet_col).to_excel(writer, sheet_name=\"bias1\")\n",
    "    pd.DataFrame(sheet_data3, columns=sheet_col).to_excel(writer, sheet_name=\"bias2\")\n",
    "    pd.DataFrame(sheet_data4, columns=sheet_col).to_excel(writer, sheet_name=\"new_bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the linear regression model is \n",
    "\n",
    "$$ y_i = \\alpha + \\beta_1 x_{i1} + \\beta_2 x_{i2} + \\varepsilon_i $$\n",
    "\n",
    "for $i \\in \\{1, \\cdots, N\\}$.\n",
    "\n",
    "Let the variance of $\\beta_j$ be $\\sigma_j^2$, so that the standard error of $\\beta_j$ is $\\sigma_j$ and the 95% confidence interval for $\\beta_j$ is\n",
    "\n",
    "$$ [\\beta_j - \\sigma_j \\times 1.96, \\beta_j + \\sigma_j \\times 1.96]$$\n",
    "\n",
    "Denote the covariance between the estimates for $\\beta_1$ and $\\beta_2$ as $\\sigma_{12}$.\n",
    "\n",
    "Define a new random variable $\\gamma = \\beta_1 + \\beta_2$. The variance of $\\gamma$ is\n",
    "\n",
    "$$ Var(\\gamma) = Var(\\beta_1 + \\beta_2) = \\sigma_1^2 + \\sigma_2^2 + 2\\sigma_{12} $$\n",
    "\n",
    "And the 95% confidence interval for $\\gamma$ is\n",
    "\n",
    "$$ [(\\beta_1 + \\beta_2) - (\\sqrt{\\sigma_1^2 + \\sigma_2^2 + 2\\sigma_{12}})\\times 1.96,\n",
    "(\\beta_1 + \\beta_2) - (\\sqrt{\\sigma_1^2 + \\sigma_2^2 + 2\\sigma_{12}})\\times 1.96] $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
