{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Random Ratio with Bias and Accuracy  \n",
    "**Bias1**:  \n",
    "$$\\Big|\\frac{FPR_{AA}}{FNR_{AA}} - \\frac{FPR_{C}}{FNR_{C}}\\Big|$$  \n",
    "**Bias2**:  \n",
    "$$\\Big|\\frac{FPR_{AA}}{FPR_{C}} - \\frac{FNR_{AA}}{FNR_{C}}\\Big|$$  \n",
    "\n",
    "$$FPR = \\frac{FP}{FP + TN}$$  \n",
    "$$FNR = \\frac{FN}{FN + TP}$$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from utils.data import create_compas_dataset, Dataset\n",
    "from utils.generator import gen_complete_random\n",
    "from utils.completer import complete_by_mean_col, complete_by_multi, complete_by_similar_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_compas_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_compas_complete = data.copy()\n",
    "tmp_concat = pd.concat([data_compas_complete.X, pd.DataFrame(data_compas_complete.y, columns=[\"_TARGET_\"])], axis=1)\n",
    "tmp_concat.dropna(inplace=True)\n",
    "tmp_concat.reset_index(drop=True, inplace=True)\n",
    "data_compas_complete.X = tmp_concat.drop(columns=[\"_TARGET_\"]).copy()\n",
    "data_compas_complete.y = tmp_concat[\"_TARGET_\"].copy().to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SVMSMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skipped Parameter Searching  \n",
    "* KNN  \n",
    "```python\n",
    "Model: KNeighborsClassifier\n",
    "Best parameter: {'leaf_size': 5, 'n_neighbors': 2}\n",
    "Acc best: 0.7061\n",
    "Acc on input data: 0.8993\n",
    "Acc on enlarged data: 0.9071\n",
    "```\n",
    "* LinearSVC  \n",
    "```python\n",
    "Model: LinearSVC\n",
    "Best parameter: {'C': 0.1, 'max_iter': 1000, 'tol': 0.001}\n",
    "Acc best: 0.6728\n",
    "Acc on input data: 0.6641\n",
    "Acc on enlarged data: 0.6725\n",
    "```\n",
    "* SVC  \n",
    "```python\n",
    "Model: SVC\n",
    "Best parameter: {'C': 10, 'max_iter': -1, 'tol': 0.0001}\n",
    "Acc best: 0.6452\n",
    "Acc on input data: 0.6285\n",
    "Acc on enlarged data: 0.6489\n",
    "```\n",
    "* Forest  \n",
    "```python\n",
    "Model: RandomForestClassifier\n",
    "Best parameter: {'max_depth': 50, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
    "Acc best: 0.7677\n",
    "Acc on input data: 0.8166\n",
    "Acc on enlarged data: 0.8567\n",
    "```\n",
    "* LogReg  \n",
    "```python\n",
    "Model: LogisticRegression\n",
    "Best parameter: {'C': 10.0, 'max_iter': 100, 'tol': 1e-05}\n",
    "Acc best: 0.6755\n",
    "Acc on input data: 0.6767\n",
    "Acc on enlarged data: 0.6762\n",
    "```\n",
    "* Tree  \n",
    "```python\n",
    "Model: DecisionTreeClassifier\n",
    "Best parameter: {'max_depth': 10, 'max_leaf_nodes': 100, 'min_samples_leaf': 1}\n",
    "Acc best: 0.7494\n",
    "Acc on input data: 0.7267\n",
    "Acc on enlarged data: 0.7765\n",
    "```\n",
    "* MLP  \n",
    "```python\n",
    "Model: MLPClassifier\n",
    "Best parameter: {'alpha': 0.0001, 'learning_rate_init': 0.01, 'max_iter': 500}\n",
    "Acc best: 0.6878\n",
    "Acc on input data: 0.6685\n",
    "Acc on enlarged data: 0.6911\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No saved data for each cross validation because it would run fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# [TN_AA, FP_AA, FN_AA, TP_AA, TN_C, FP_C, FN_C, TP_C]\n",
    "def bias1(data):\n",
    "    # input should be data from compute_confusion_matrix\n",
    "    # bias 1 = |(FPR_AA/FNR_AA) - (FPR_C/FNR_C)|\n",
    "    FPR_AA = data[1] / (data[1] + data[0])\n",
    "    FNR_AA = data[2] / (data[2] + data[3])\n",
    "    FPR_C  = data[5] / (data[5] + data[4])\n",
    "    FNR_C  = data[6] / (data[6] + data[7])\n",
    "    if FNR_AA == 0 or FNR_C == 0: return -1 # mark error situation\n",
    "    bias = (FPR_AA / FNR_AA) - (FPR_C / FNR_C)\n",
    "    return abs(bias)\n",
    "   \n",
    "def bias2(data):\n",
    "    # input should be data from compute_confusion_matrix\n",
    "    # bias 2 = |(FPR_AA/FPR_C) - (FNR_AA/FNR_C)|\n",
    "    FPR_AA = data[1] / (data[1] + data[0])\n",
    "    FNR_AA = data[2] / (data[2] + data[3])\n",
    "    FPR_C  = data[5] / (data[5] + data[4])\n",
    "    FNR_C  = data[6] / (data[6] + data[7])\n",
    "    if FNR_C == 0 or FPR_C == 0: return -1 # mark error situation\n",
    "    bias = (FPR_AA / FPR_C) - (FNR_AA / FNR_C)\n",
    "    return abs(bias)\n",
    "\n",
    "def acc(data):\n",
    "    # input should be data from compute_confusion_matrix\n",
    "    # acc = (TP + TN) / (TP + TN + FP + FN)\n",
    "    TP = data[3] + data[7]\n",
    "    TN = data[0] + data[4]\n",
    "    accuracy = (TP + TN) / sum(data)\n",
    "    return accuracy\n",
    "\n",
    "def helper_freq(array):\n",
    "    \"\"\"simple helper function to return the most frequent number in an array\"\"\"\n",
    "    count = np.bincount(array)\n",
    "    return array[np.argmax(count)]\n",
    "\n",
    "#def average_cv(cv_data):\n",
    "#    # compute average for the confusion matrix data for each fold\n",
    "#    result = {}\n",
    "#    for name, data in cv_data.items():\n",
    "#        new_data = {\n",
    "#            \"African-American\": np.array([m[\"African-American\"] for m in data]).mean(axis=0).tolist(),\n",
    "#            \"Caucasian\": np.array([m[\"Caucasian\"] for m in data]).mean(axis=0).tolist()\n",
    "#        }\n",
    "#        result[name] = new_data\n",
    "#    return result\n",
    "\n",
    "def compute_confusion_matrix(X_train, y_train, X_test, y_test, clf, protected_features, multi=False):\n",
    "    # X are pandas dataframe\n",
    "    # y are numpy array\n",
    "    # clf is a sklearn classifier\n",
    "    # protected_features is list\n",
    "    smote = SVMSMOTE(random_state=22)\n",
    "    if not multi:\n",
    "        X_train = X_train.drop(columns=protected_features).copy().to_numpy()\n",
    "        X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "        clf.fit(X_train_res, y_train_res)\n",
    "        # print(\"Acc: {:.4f}\".format(clf.score(X_test.drop(columns=protected_features).copy().to_numpy(), y_test)), end=\" \")\n",
    "        X_test_AA = X_test[X_test[\"race\"] == \"African-American\"].drop(columns=protected_features).to_numpy()\n",
    "        X_test_C = X_test[X_test[\"race\"] == \"Caucasian\"].drop(columns=protected_features).to_numpy()\n",
    "        y_test_AA = y_test[X_test[X_test[\"race\"] == \"African-American\"].index.tolist()]\n",
    "        y_test_C = y_test[X_test[X_test[\"race\"] == \"Caucasian\"].index.tolist()]\n",
    "        matrix_AA = confusion_matrix(y_test_AA, clf.predict(X_test_AA))\n",
    "        matrix_C = confusion_matrix(y_test_C, clf.predict(X_test_C))\n",
    "    else:\n",
    "        prediction_AA = []\n",
    "        prediction_C = []\n",
    "        X_test_first = X_test[0]\n",
    "        y_test_AA = y_test[X_test_first[X_test_first[\"race\"] == \"African-American\"].index.tolist()]\n",
    "        y_test_C = y_test[X_test_first[X_test_first[\"race\"] == \"Caucasian\"].index.tolist()]\n",
    "        scores = [0, 0]\n",
    "        for X_train_m in X_train:\n",
    "            X_train_m = X_train_m.drop(columns=protected_features).copy().to_numpy()\n",
    "            X_train_res, y_train_res = smote.fit_resample(X_train_m, y_train)\n",
    "            clf.fit(X_train_res, y_train_res)\n",
    "            for X_test_m in X_test:\n",
    "                X_test_AA = X_test_m[X_test_m[\"race\"] == \"African-American\"].drop(columns=protected_features).to_numpy()\n",
    "                X_test_C = X_test_m[X_test_m[\"race\"] == \"Caucasian\"].drop(columns=protected_features).to_numpy()\n",
    "                prediction_AA.append(clf.predict(X_test_AA))\n",
    "                prediction_C.append(clf.predict(X_test_C))\n",
    "                scores[0] += clf.score(X_test_m.drop(columns=protected_features).copy().to_numpy(), y_test)\n",
    "                scores[1] += 1\n",
    "        # print(\"Acc: {:.4f}\".format(scores[0] / scores[1]), end=\" \")\n",
    "        # compute final predictions by voting\n",
    "        prediction_AA = np.apply_along_axis(helper_freq, 0, np.array(prediction_AA))\n",
    "        prediction_C = np.apply_along_axis(helper_freq, 0, np.array(prediction_C))\n",
    "        matrix_AA = confusion_matrix(y_test_AA, prediction_AA)\n",
    "        matrix_C = confusion_matrix(y_test_C, prediction_C)\n",
    "    #result = {\n",
    "    #    \"African-American\": matrix_AA.ravel().tolist(), # [tn, fp, fn, tp]\n",
    "    #    \"Caucasian\": matrix_C.ravel().tolist()\n",
    "    #}\n",
    "    # [TN_AA, FP_AA, FN_AA, TP_AA, TN_C, FP_C, FN_C, TP_C]\n",
    "    result = matrix_AA.ravel().tolist() + matrix_C.ravel().tolist()\n",
    "    return result\n",
    "\n",
    "def test_imputation(X, y, protected_features, completer_func=None, multi=False):\n",
    "    # X is pandas dataframe\n",
    "    # y is numpy array,\n",
    "    # protected_features is list\n",
    "    # completer func is the imputation function\n",
    "    global all_params\n",
    "    clfs = { # define all the classifiers with best parameters\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=2, leaf_size=5),\n",
    "        \"LinearSVC\": LinearSVC(dual=False, tol=0.001, C=0.1, max_iter=1000),\n",
    "        \"SVC\": SVC(tol=0.0001, C=10, max_iter=-1),\n",
    "        \"Forest\": RandomForestClassifier(n_estimators=100, max_depth=50, min_samples_leaf=5),\n",
    "        \"LogReg\": LogisticRegression(tol=1e-5, C=10, max_iter=100),\n",
    "        \"Tree\": DecisionTreeClassifier(max_depth=10, max_leaf_nodes=100, min_samples_leaf=1),\n",
    "        \"MLP\": MLPClassifier(alpha=0.0001, learning_rate_init=0.01, max_iter=500),\n",
    "    }\n",
    "    acc_cv = { # save each accuracy output cv\n",
    "        \"KNN\": [],\n",
    "        \"LinearSVC\": [],\n",
    "        \"SVC\": [],\n",
    "        \"Forest\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"Tree\": [],\n",
    "        \"MLP\": [],\n",
    "    }\n",
    "    bias1_cv = { # save each bias 1 outputs cv\n",
    "        \"KNN\": [],\n",
    "        \"LinearSVC\": [],\n",
    "        \"SVC\": [],\n",
    "        \"Forest\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"Tree\": [],\n",
    "        \"MLP\": [],\n",
    "    }\n",
    "    bias2_cv = { # save each bias 2 outputs cv\n",
    "        \"KNN\": [],\n",
    "        \"LinearSVC\": [],\n",
    "        \"SVC\": [],\n",
    "        \"Forest\": [],\n",
    "        \"LogReg\": [],\n",
    "        \"Tree\": [],\n",
    "        \"MLP\": [],\n",
    "    }\n",
    "    kf = KFold(n_splits=10, shuffle=True)\n",
    "    fold = 1\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        # print(\"Fold {:>2}\".format(fold), end=\" \")\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        if completer_func:\n",
    "        # do imputations on training set and test set individually\n",
    "            data_incomplete = Dataset(\"tmp\", X_train, y_train, auto_convert=False, protected_features=protected_features)\n",
    "            data_complete = completer_func(data_incomplete)\n",
    "            X_train = [m.X.copy() for m in data_complete] if multi else data_complete.X.copy() \n",
    "            y_train = data_complete[0].y.copy() if multi else data_complete.y.copy()\n",
    "            data_incomplete = Dataset(\"tmp\", X_test, y_test, auto_convert=False, protected_features=protected_features)\n",
    "            data_complete = completer_func(data_incomplete)\n",
    "            X_test = [m.X.copy() for m in data_complete] if multi else data_complete.X.copy()\n",
    "            y_test = data_complete[0].y.copy() if multi else data_complete.y.copy()\n",
    "        # get result for each classifier\n",
    "        for clf_name, clf in clfs.items():\n",
    "            # print(\"{}\".format(clf_name), end=\" \")\n",
    "            result = compute_confusion_matrix(X_train, y_train, X_test, y_test, clf, protected_features, multi=multi)\n",
    "            acc_cv[clf_name].append(acc(result))\n",
    "            bias1_cv[clf_name].append(bias1(result))\n",
    "            bias2_cv[clf_name].append(bias2(result))\n",
    "        # print()\n",
    "        fold += 1\n",
    "    # print(\"Result:\\n{}\".format(data_cv))\n",
    "    return (acc_cv, bias1_cv, bias2_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-threaded run (and never run this on Windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ratios = np.linspace(0.0, 1.0, num=20, endpoint=False) # 20 ratios\n",
    "results = {\n",
    "    \"mean\":    None,\n",
    "    \"similar\": None,\n",
    "    \"multi\":   None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete by Mean Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_mean_task(idx):\n",
    "    data_sim = gen_complete_random(data_compas_complete, random_ratio=random_ratios[idx], print_all=False)\n",
    "    result = test_imputation(data_sim.X.copy(), data_sim.y.copy(),\n",
    "                             data_sim.protected, complete_by_mean_col, multi=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [16:33<00:00, 49.70s/it]  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=6) as pool:\n",
    "        results[\"mean\"] = list(tqdm.tqdm(pool.imap(complete_mean_task, range(len(random_ratios))), total=len(random_ratios)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete by Similar Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_similar_task(idx):\n",
    "    data_sim = gen_complete_random(data_compas_complete, random_ratio=random_ratios[idx], print_all=False)\n",
    "    result = test_imputation(data_sim.X.copy(), data_sim.y.copy(),\n",
    "                             data_sim.protected, complete_by_similar_row, multi=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [16:07<00:00, 48.35s/it]  \n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=7) as pool:\n",
    "        results[\"similar\"] = list(tqdm.tqdm(pool.imap(complete_similar_task, range(len(random_ratios))), total=len(random_ratios)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete by Multiple Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_multi_task(idx):\n",
    "    data_sim = gen_complete_random(data_compas_complete, random_ratio=random_ratios[idx], print_all=False)\n",
    "    result = test_imputation(data_sim.X.copy(), data_sim.y.copy(),\n",
    "                             data_sim.protected, complete_by_multi, multi=True)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [1:17:39<24:17, 242.87s/it]  "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    with Pool(processes=7) as pool:\n",
    "        results[\"multi\"] = list(tqdm.tqdm(pool.imap(complete_multi_task, range(len(random_ratios))), total=len(random_ratios)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(name, save_file=None):\n",
    "    global results\n",
    "    classifiers = [\"KNN\", \"LinearSVC\", \"SVC\", \"Forest\", \"LogReg\", \"Tree\", \"MLP\"]\n",
    "    result = results[name]\n",
    "    d_acc = [x[0] for x in result]   # len of random_ratios\n",
    "    d_bias1 = [x[1] for x in result] # len of random_ratios\n",
    "    d_bias2 = [x[2] for x in result] # len of random_ratios\n",
    "    assert len(d_acc) == len(d_bias1) and len(d_acc) == len(d_bias2) and len(d_acc) == len(random_ratios)\n",
    "    plot_bias1 = {}\n",
    "    plot_bias2 = {}\n",
    "    plot_acc = {}\n",
    "    for clf in classifiers:\n",
    "        plot_bias1[clf] = [[], []] # plot data: [Y values, num excluded trials (-1 situations)]\n",
    "        plot_bias2[clf] = [[], []]\n",
    "        plot_acc[clf]   = [[], []]\n",
    "    for i in range(len(d_acc)):\n",
    "        i_acc = d_acc[i]\n",
    "        i_bias1 = d_bias1[i]\n",
    "        i_bias2 = d_bias2[i]\n",
    "        for clf in classifiers:\n",
    "            mat = [i_acc[clf], i_bias1[clf], i_bias2[clf]]\n",
    "            assert len(mat[0]) == len(mat[1]) and len(mat[0]) == len(mat[2])\n",
    "            counter = 0 # count for -1\n",
    "            total_len = len(mat[0])\n",
    "            s_acc, s_bias1, s_bias2 = 0, 0, 0 # sum\n",
    "            for j in range(total_len):\n",
    "                if(mat[1][j] != -1 and mat[2][j] != -1):\n",
    "                    s_acc += mat[0][j]\n",
    "                    s_bias1 += mat[1][j]\n",
    "                    s_bias2 += mat[2][j]\n",
    "                else: counter += 1\n",
    "            plot_bias1[clf][0].append(s_bias1 / (total_len-counter))\n",
    "            plot_bias1[clf][1].append(counter*5 + 4) # 1 for minimum marker size\n",
    "            plot_bias2[clf][0].append(s_bias2 / (total_len-counter))\n",
    "            plot_bias2[clf][1].append(counter*5 + 4)\n",
    "            plot_acc[clf][0].append(s_acc / (total_len-counter))\n",
    "            plot_acc[clf][1].append(counter*5 + 4)\n",
    "    fig, axes = plt.subplots(3, figsize=(10, 15))\n",
    "    # axes[0] shows bias1\n",
    "    axes[0].set_title(\"Bias1\")\n",
    "    for clf in classifiers:\n",
    "        axes[0].plot(random_ratios, plot_bias1[clf][0], label=clf)\n",
    "        axes[0].scatter(random_ratios, plot_bias1[clf][0], s=plot_bias1[clf][1])\n",
    "    axes[0].legend(loc=\"best\")\n",
    "    axes[0].set_xticks(np.arange(0.0, 1.0, 0.05))\n",
    "    # axes[1] shows bias2\n",
    "    axes[1].set_title(\"Bias2\")\n",
    "    for clf in classifiers:\n",
    "        axes[1].plot(random_ratios, plot_bias2[clf][0], label=clf)\n",
    "        axes[1].scatter(random_ratios, plot_bias2[clf][0], s=plot_bias2[clf][1])\n",
    "    axes[1].legend(loc=\"best\")\n",
    "    axes[1].set_xticks(np.arange(0.0, 1.0, 0.05))\n",
    "    # axes[2] shows accuracy\n",
    "    axes[2].set_title(\"Accuracy\")\n",
    "    for clf in classifiers:\n",
    "        axes[2].plot(random_ratios, plot_acc[clf][0], label=clf)\n",
    "        axes[2].scatter(random_ratios, plot_acc[clf][0], s=plot_acc[clf][1])\n",
    "    axes[2].legend(loc=\"best\")\n",
    "    axes[2].set_xticks(np.arange(0.0, 1.0, 0.05))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"Imputation Method: {}\".format(name))\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    if save_file:\n",
    "        fig.savefig(save_file, transparent=False, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"mean\", \"ratio_mean.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"similar\", \"ratio_similar.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_result(\"multi\", \"ratio_multi.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
